{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manelsaddouki/KNN-Classification/blob/main/ANN_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMtv7bUXZnNH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.utils import np_utils"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.random import seed\n",
        "seed(1)\n",
        "from tensorflow import random\n",
        "random.set_seed(1)"
      ],
      "metadata": {
        "id": "sQXP6IB0K9O6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import the dataset**"
      ],
      "metadata": {
        "id": "juyy1O6YcEtf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=pd.read_csv(r'/content/sample_data/Churn_Modelling.csv',sep=\",\")"
      ],
      "metadata": {
        "id": "5oxfDKgcZ0Tc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAbwNysna384",
        "outputId": "267c18be-de60-4b56-df91-6736b433d896"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 14)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = dataset.iloc[:, 3:13].values"
      ],
      "metadata": {
        "id": "RN_4K3G6aZ8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = dataset.iloc[:, 13].values\n",
        "Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qg54FQbpashW",
        "outputId": "ebb7dbf6-d0f7-4343-91b5-8229c99b2442"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, ..., 1, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Transform the class labels into dummies variables**"
      ],
      "metadata": {
        "id": "KYA425X3cIsc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "labelencoder_X_1 = LabelEncoder()\n",
        "X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\n",
        "labelencoder_X_2 = LabelEncoder()\n",
        "X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])\n",
        "\n",
        "\n",
        "transformer = ColumnTransformer([('one_hot_encoder', OneHotEncoder(), [1])],remainder='passthrough')\n",
        "X = np.array(transformer.fit_transform(X))"
      ],
      "metadata": {
        "id": "FtK8DgEQKxc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split the data at random into training and test sets (80% vs 20 %)**"
      ],
      "metadata": {
        "id": "jnoxaNjmcUss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2,random_state=0)"
      ],
      "metadata": {
        "id": "CHsSh5HdOaBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape,\n",
        "Y_train.shape,\n",
        "X_test.shape,\n",
        "Y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_mIai-POeMq",
        "outputId": "a479532f-b839-4f24-8521-046156d71cc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8000, 12) (8000,) (2000, 12) (2000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Architecture and implementation of the neural network to use**"
      ],
      "metadata": {
        "id": "UdMRRmvocbXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten"
      ],
      "metadata": {
        "id": "nAmqD4OhOhcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below code will create the given network. The first add will take care of the input layer."
      ],
      "metadata": {
        "id": "TCkp_Xg3ciBU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(units=12, kernel_initializer='uniform', activation='relu', input_dim=12))\n",
        "model.add(Dense(units=12, kernel_initializer='uniform', activation='relu'))\n",
        "model.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))"
      ],
      "metadata": {
        "id": "XPmYSpNUOlQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a next step we compile the model to get the compiled architecture."
      ],
      "metadata": {
        "id": "tdDJZ76KcjJb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "DrfLzfsGQcnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPeN_PubQjzp",
        "outputId": "d5c3addf-64be-4fdd-cfe6-50554ed6a055"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_25 (Dense)            (None, 12)                156       \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 12)                156       \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 1)                 13        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 325\n",
            "Trainable params: 325\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " print(model.get_weights())"
      ],
      "metadata": {
        "id": "n6WuZYAgQoux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training of the ANN model"
      ],
      "metadata": {
        "id": "rHgeUjBDcpiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=np.asarray(X_train).astype(np.int)\n",
        "\n",
        "Y_train=np.asarray(Y_train).astype(np.int)\n",
        "\n",
        "model.fit(X_train, Y_train, batch_size=4, epochs=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBxvoaFCQw1x",
        "outputId": "976127ff-9966-4bb4-d086-afd07fed09bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-82-4f3083e39732>:1: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  X_train=np.asarray(X_train).astype(np.int)\n",
            "<ipython-input-82-4f3083e39732>:3: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  Y_train=np.asarray(Y_train).astype(np.int)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2000/2000 [==============================] - 3s 1ms/step - loss: 0.6004 - accuracy: 0.7846\n",
            "Epoch 2/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5472 - accuracy: 0.7960\n",
            "Epoch 3/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5369 - accuracy: 0.7959\n",
            "Epoch 4/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5341 - accuracy: 0.7960\n",
            "Epoch 5/128\n",
            "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5318 - accuracy: 0.7960\n",
            "Epoch 6/128\n",
            "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5293 - accuracy: 0.7960\n",
            "Epoch 7/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5245 - accuracy: 0.7960\n",
            "Epoch 8/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5348 - accuracy: 0.7960\n",
            "Epoch 9/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5283 - accuracy: 0.7960\n",
            "Epoch 10/128\n",
            "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5335 - accuracy: 0.7960\n",
            "Epoch 11/128\n",
            "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5405 - accuracy: 0.7959\n",
            "Epoch 12/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5333 - accuracy: 0.7955\n",
            "Epoch 13/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5320 - accuracy: 0.7960\n",
            "Epoch 14/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5403 - accuracy: 0.7960\n",
            "Epoch 15/128\n",
            "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5333 - accuracy: 0.7960\n",
            "Epoch 16/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5312 - accuracy: 0.7960\n",
            "Epoch 17/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5326 - accuracy: 0.7960\n",
            "Epoch 18/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5303 - accuracy: 0.7959\n",
            "Epoch 19/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5340 - accuracy: 0.7960\n",
            "Epoch 20/128\n",
            "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5311 - accuracy: 0.7960\n",
            "Epoch 21/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5318 - accuracy: 0.7960\n",
            "Epoch 22/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5293 - accuracy: 0.7959\n",
            "Epoch 23/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5268 - accuracy: 0.7960\n",
            "Epoch 24/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5304 - accuracy: 0.7959\n",
            "Epoch 25/128\n",
            "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5302 - accuracy: 0.7959\n",
            "Epoch 26/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5255 - accuracy: 0.7956\n",
            "Epoch 27/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5328 - accuracy: 0.7960\n",
            "Epoch 28/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5281 - accuracy: 0.7960\n",
            "Epoch 29/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5289 - accuracy: 0.7960\n",
            "Epoch 30/128\n",
            "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5416 - accuracy: 0.7960\n",
            "Epoch 31/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5441 - accuracy: 0.7960\n",
            "Epoch 32/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5311 - accuracy: 0.7956\n",
            "Epoch 33/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5334 - accuracy: 0.7959\n",
            "Epoch 34/128\n",
            "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5352 - accuracy: 0.7960\n",
            "Epoch 35/128\n",
            "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5344 - accuracy: 0.7960\n",
            "Epoch 36/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5292 - accuracy: 0.7960\n",
            "Epoch 37/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5272 - accuracy: 0.7960\n",
            "Epoch 38/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5322 - accuracy: 0.7960\n",
            "Epoch 39/128\n",
            "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5247 - accuracy: 0.7960\n",
            "Epoch 40/128\n",
            "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5279 - accuracy: 0.7958\n",
            "Epoch 41/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5358 - accuracy: 0.7960\n",
            "Epoch 42/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5315 - accuracy: 0.7960\n",
            "Epoch 43/128\n",
            "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5312 - accuracy: 0.7956\n",
            "Epoch 44/128\n",
            "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5474 - accuracy: 0.7960\n",
            "Epoch 45/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5346 - accuracy: 0.7956\n",
            "Epoch 46/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5304 - accuracy: 0.7955\n",
            "Epoch 47/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5297 - accuracy: 0.7960\n",
            "Epoch 48/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5394 - accuracy: 0.7960\n",
            "Epoch 49/128\n",
            "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5288 - accuracy: 0.7960\n",
            "Epoch 50/128\n",
            "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5338 - accuracy: 0.7960\n",
            "Epoch 51/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5288 - accuracy: 0.7960\n",
            "Epoch 52/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5285 - accuracy: 0.7952\n",
            "Epoch 53/128\n",
            "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5379 - accuracy: 0.7959\n",
            "Epoch 54/128\n",
            "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5378 - accuracy: 0.7960\n",
            "Epoch 55/128\n",
            "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5352 - accuracy: 0.7934\n",
            "Epoch 56/128\n",
            "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5327 - accuracy: 0.7949\n",
            "Epoch 57/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5253 - accuracy: 0.7960\n",
            "Epoch 58/128\n",
            "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5228 - accuracy: 0.7956\n",
            "Epoch 59/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5208 - accuracy: 0.7960\n",
            "Epoch 60/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5277 - accuracy: 0.7958\n",
            "Epoch 61/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5249 - accuracy: 0.7958\n",
            "Epoch 62/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5307 - accuracy: 0.7960\n",
            "Epoch 63/128\n",
            "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5257 - accuracy: 0.7960\n",
            "Epoch 64/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5302 - accuracy: 0.7946\n",
            "Epoch 65/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5254 - accuracy: 0.7959\n",
            "Epoch 66/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5296 - accuracy: 0.7960\n",
            "Epoch 67/128\n",
            "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5274 - accuracy: 0.7960\n",
            "Epoch 68/128\n",
            "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5351 - accuracy: 0.7960\n",
            "Epoch 69/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5303 - accuracy: 0.7960\n",
            "Epoch 70/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5322 - accuracy: 0.7960\n",
            "Epoch 71/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5314 - accuracy: 0.7958\n",
            "Epoch 72/128\n",
            "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5321 - accuracy: 0.7951\n",
            "Epoch 73/128\n",
            "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5365 - accuracy: 0.7960\n",
            "Epoch 74/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5267 - accuracy: 0.7960\n",
            "Epoch 75/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5271 - accuracy: 0.7960\n",
            "Epoch 76/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5314 - accuracy: 0.7960\n",
            "Epoch 77/128\n",
            "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5297 - accuracy: 0.7958\n",
            "Epoch 78/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5277 - accuracy: 0.7960\n",
            "Epoch 79/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5294 - accuracy: 0.7960\n",
            "Epoch 80/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5390 - accuracy: 0.7960\n",
            "Epoch 81/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5365 - accuracy: 0.7960\n",
            "Epoch 82/128\n",
            "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5265 - accuracy: 0.7958\n",
            "Epoch 83/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5287 - accuracy: 0.7960\n",
            "Epoch 84/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5273 - accuracy: 0.7959\n",
            "Epoch 85/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5270 - accuracy: 0.7960\n",
            "Epoch 86/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5260 - accuracy: 0.7960\n",
            "Epoch 87/128\n",
            "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5320 - accuracy: 0.7960\n",
            "Epoch 88/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5274 - accuracy: 0.7958\n",
            "Epoch 89/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5270 - accuracy: 0.7958\n",
            "Epoch 90/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5242 - accuracy: 0.7960\n",
            "Epoch 91/128\n",
            "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5206 - accuracy: 0.7959\n",
            "Epoch 92/128\n",
            "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5280 - accuracy: 0.7956\n",
            "Epoch 93/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5295 - accuracy: 0.7959\n",
            "Epoch 94/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5230 - accuracy: 0.7959\n",
            "Epoch 95/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5259 - accuracy: 0.7960\n",
            "Epoch 96/128\n",
            "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5278 - accuracy: 0.7960\n",
            "Epoch 97/128\n",
            "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5352 - accuracy: 0.7954\n",
            "Epoch 98/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5272 - accuracy: 0.7960\n",
            "Epoch 99/128\n",
            "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5285 - accuracy: 0.7960\n",
            "Epoch 100/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5318 - accuracy: 0.7960\n",
            "Epoch 101/128\n",
            "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5282 - accuracy: 0.7959\n",
            "Epoch 102/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5282 - accuracy: 0.7960\n",
            "Epoch 103/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5303 - accuracy: 0.7960\n",
            "Epoch 104/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5236 - accuracy: 0.7960\n",
            "Epoch 105/128\n",
            "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5287 - accuracy: 0.7960\n",
            "Epoch 106/128\n",
            "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5245 - accuracy: 0.7960\n",
            "Epoch 107/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5275 - accuracy: 0.7960\n",
            "Epoch 108/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5282 - accuracy: 0.7960\n",
            "Epoch 109/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5225 - accuracy: 0.7960\n",
            "Epoch 110/128\n",
            "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5289 - accuracy: 0.7960\n",
            "Epoch 111/128\n",
            "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5279 - accuracy: 0.7960\n",
            "Epoch 112/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5297 - accuracy: 0.7960\n",
            "Epoch 113/128\n",
            "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5289 - accuracy: 0.7960\n",
            "Epoch 114/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5244 - accuracy: 0.7960\n",
            "Epoch 115/128\n",
            "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5236 - accuracy: 0.7960\n",
            "Epoch 116/128\n",
            "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5227 - accuracy: 0.7960\n",
            "Epoch 117/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5233 - accuracy: 0.7960\n",
            "Epoch 118/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5209 - accuracy: 0.7960\n",
            "Epoch 119/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5221 - accuracy: 0.7960\n",
            "Epoch 120/128\n",
            "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5224 - accuracy: 0.7960\n",
            "Epoch 121/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5213 - accuracy: 0.7960\n",
            "Epoch 122/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5216 - accuracy: 0.7960\n",
            "Epoch 123/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5235 - accuracy: 0.7960\n",
            "Epoch 124/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5225 - accuracy: 0.7960\n",
            "Epoch 125/128\n",
            "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5205 - accuracy: 0.7960\n",
            "Epoch 126/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5257 - accuracy: 0.7959\n",
            "Epoch 127/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5263 - accuracy: 0.7959\n",
            "Epoch 128/128\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.5394 - accuracy: 0.7960\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f42b547dd50>"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model evaluation**"
      ],
      "metadata": {
        "id": "SQTWzkmfcv9P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test=np.asarray(X_test).astype(np.int)\n",
        "\n",
        "Y_test=np.asarray(Y_test).astype(np.int)\n",
        "\n",
        "score=model.evaluate(X_test,Y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KN1IzdBZDk_",
        "outputId": "69f64e4e-9627-473b-abb8-28170a1f45ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 1ms/step - loss: 0.5083 - accuracy: 0.7975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-92-1a77a7512f33>:1: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  X_test=np.asarray(X_test).astype(np.int)\n",
            "<ipython-input-92-1a77a7512f33>:3: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  Y_test=np.asarray(Y_test).astype(np.int)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model is 79.75% accurate"
      ],
      "metadata": {
        "id": "5K8aSTnCczyS"
      }
    }
  ]
}